# Ollama Local AI Model Server for Intelluxe AI Healthcare System
# Privacy-first local LLM serving with HIPAA compliance for clinical workflows
image=ollama/ollama:latest
port=11434:11434
description=Local AI model server for Intelluxe AI healthcare workflows with HIPAA compliance
# Ollama API server for clinical AI inference
env=OLLAMA_HOST=0.0.0.0,OLLAMA_KEEP_ALIVE=24h,OLLAMA_MAX_LOADED_MODELS=2,HEALTHCARE_MODE=true,OLLAMA_ORIGINS=*
# Shared model storage for efficient healthcare AI deployment
volumes=shared-ollama-models:/root/.ollama,shared-ollama-config:/config:ro,intelluxe-audit-logs:/app/logs
network_mode=intelluxe-net
static_ip=172.20.0.10
restart_policy=unless-stopped
domain_routing=true
healthcheck=ollama list || exit 1
# Maximum GPU utilization for healthcare AI workloads with audit logging
gpus=all
runtime=nvidia
memory=20g
read_only=false
security_opt=no-new-privileges
